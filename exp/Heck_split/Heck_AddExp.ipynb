{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GiZXYx7ULFpG"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install rdkit"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Y1M-c1jNLfYA","executionInfo":{"status":"ok","timestamp":1730288407719,"user_tz":-480,"elapsed":7640,"user":{"displayName":"Shen Wang","userId":"04706405006580685920"}}},"outputs":[],"source":["import os\n","import sys\n","import torch\n","import time\n","import datetime\n","from tqdm import tqdm\n","sys.path.append(\"/content/drive/MyDrive/HeckLit\")\n","from utils.rxn import *\n","from utils.molecule import *\n","from torch.utils.data import DataLoader\n","from models.ANN import *\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpPxZL2EOaXo"},"outputs":[],"source":["rs_list = [1, 2, 3, 4, 5]\n","for rs in rs_list:\n","    # 1. import data\n","    random_state = rs\n","    data_Heck = pd.read_excel(\"/content/drive/MyDrive/HeckLit/data/Heck/Heck_fp.xlsx\").sample(\n","        random_state=random_state, frac=1).reset_index(drop=True)\n","    data_BH = pd.read_excel(\"/content/drive/MyDrive/HeckLit/data/BH_HTE/BH_HTE_fp.xlsx\").sample(\n","        random_state=random_state, frac=1).reset_index(drop=True)\n","    data_Suzuki = pd.read_excel(\"/content/drive/MyDrive/HeckLit/data/Suzuki_HTE/Suzuki_HTE_fp.xlsx\").sample(\n","        random_state=random_state, frac=1).reset_index(drop=True)\n","    # 2. build dataset & dataloader\n","    intra_dataset = list()\n","    inter_dataset = list()\n","    BH_dataset = list()\n","    Suzuki_dataset = list()\n","\n","    rxn_list = df_to_rxn_list(data_Heck)\n","    len_drfp = 0\n","\n","    for batch in tqdm(range(data_Heck.shape[0])):\n","        rxn = rxn_list[batch]\n","\n","        # features\n","        drfp = torch.tensor(read_drfp(data_Heck.loc[batch][\"drfp\"]), dtype=torch.float32)\n","        len_drfp = drfp.shape[0]\n","        # label\n","        y = rxn.rxn_yield / 100\n","\n","        # Inter\n","        if len(rxn.reactants) == 2:\n","            inter_dataset.append([drfp, y])\n","\n","        # Intra\n","        if len(rxn.reactants) == 1:\n","            intra_dataset.append([drfp, y])\n","\n","    # BH\n","    for batch in tqdm(range(data_BH.shape[0])):\n","        # features\n","        drfp = torch.tensor(read_drfp(data_BH.loc[batch][\"drfp\"]), dtype=torch.float32)\n","        len_drfp = drfp.shape[0]\n","\n","        # label\n","        y = data_BH.loc[batch][\"yield\"] / 100\n","        BH_dataset.append([drfp, y])\n","\n","    # Suzuki\n","    for batch in tqdm(range(data_Suzuki.shape[0])):\n","        # features\n","        drfp = torch.tensor(read_drfp(data_Suzuki.loc[batch][\"drfp\"]), dtype=torch.float32)\n","        len_drfp = drfp.shape[0]\n","\n","        # label\n","        y = data_Suzuki.loc[batch][\"Product_Yield_PCT_Area_UV\"] / 100\n","        Suzuki_dataset.append([drfp, y])\n","\n","    # report\n","    dir_path = \"/content/drive/MyDrive/HeckLit/exp/Heck_split/Heck_drfp_add_%s\" % datetime.datetime.now()\n","    os.mkdir(\"%s\" % dir_path)\n","    f = open(\"%s/Model_Training_Report.txt\" % dir_path, mode=\"w\")\n","\n","    # split of train & test set\n","    n_base = 16  # intra sample number\n","    n_sample = 1024  # total sample number\n","    batch_size = 465\n","    f.write(\"random_state=%s\\n\" % random_state)\n","    f.write(\"n_base=%s\\n\" % n_base)\n","    f.write(\"n_sample=%s\\n\" % n_sample)\n","    f.write(\"batch_size=%s\\n\" % batch_size)\n","\n","    test_num = len(intra_dataset) - 1024\n","    testset = intra_dataset[-test_num:]\n","    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","    # intra\n","    intra_trainset = intra_dataset[0: n_sample]\n","    # data_loader\n","    intra_train_loader = DataLoader(intra_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","    intra_test_RMSE = list()\n","    intra_test_R2 = list()\n","    intra_train_R2 = list()\n","    intra_train_RMSE = list()\n","\n","    # inter\n","    inter_trainset = intra_dataset[: n_base] + inter_dataset[: n_sample - n_base]\n","    # data_loader\n","    inter_train_loader = DataLoader(inter_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","    inter_test_RMSE = list()\n","    inter_test_R2 = list()\n","    inter_train_R2 = list()\n","    inter_train_RMSE = list()\n","\n","    # BH\n","    BH_trainset = intra_dataset[: n_base] + BH_dataset[: n_sample - n_base]\n","    # data_loader\n","    BH_train_loader = DataLoader(BH_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","    BH_test_RMSE = list()\n","    BH_test_R2 = list()\n","    BH_train_R2 = list()\n","    BH_train_RMSE = list()\n","\n","    # Suzuki\n","    Suzuki_trainset = intra_dataset[: n_base] + Suzuki_dataset[: n_sample - n_base]\n","    # data_loader\n","    Suzuki_train_loader = DataLoader(Suzuki_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","    Suzuki_test_RMSE = list()\n","    Suzuki_test_R2 = list()\n","    Suzuki_train_R2 = list()\n","    Suzuki_train_RMSE = list()\n","\n","    # 3. training of the model\n","\n","    # use gpu\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # intra\n","    # params\n","    intra_t = 2500\n","    intra_lr = 1e-4\n","\n","    # model\n","    intra_model = ANN(input_size=len_drfp).to(device)\n","    intra_opti = torch.optim.Adam(intra_model.parameters(), lr=intra_lr, weight_decay=1e-5)\n","    intra_criterion = nn.MSELoss()\n","\n","    # writedown params\n","    f.write(\"\\nIntra params:\\n\")\n","    f.write(\"intra_t=%s\\n\" % intra_t)\n","    f.write(\"intra_lr=%s\\n\" % intra_lr)\n","\n","    # inter\n","    # params\n","    inter_t = 2500\n","    inter_lr = 1e-4\n","\n","    # model\n","    inter_model = ANN(input_size=len_drfp).to(device)\n","    inter_opti = torch.optim.Adam(inter_model.parameters(), lr=inter_lr, weight_decay=1e-5)\n","    inter_criterion = nn.MSELoss()\n","\n","    # writedown params\n","    f.write(\"\\nInter params:\\n\")\n","    f.write(\"inter_t=%s\\n\" % inter_t)\n","    f.write(\"inter_lr=%s\\n\" % inter_lr)\n","\n","    # BH\n","    # params\n","    BH_t = 2500\n","    BH_lr = 1e-3\n","\n","    # model\n","    BH_model = ANN(input_size=len_drfp).to(device)\n","    BH_opti = torch.optim.Adam(BH_model.parameters(), lr=BH_lr, weight_decay=1e-5)\n","    BH_criterion = nn.MSELoss()\n","\n","    # writedown params\n","    f.write(\"\\nBH params:\\n\")\n","    f.write(\"BH_t=%s\\n\" % inter_t)\n","    f.write(\"BH_lr=%s\\n\" % inter_lr)\n","\n","    # Suzuki\n","    # params\n","    Suzuki_t = 2500\n","    Suzuki_lr = 1e-3\n","\n","    # model\n","    Suzuki_model = ANN(input_size=len_drfp).to(device)\n","    Suzuki_opti = torch.optim.Adam(Suzuki_model.parameters(), lr=Suzuki_lr, weight_decay=1e-5)\n","    Suzuki_criterion = nn.MSELoss()\n","\n","    # writedown params\n","    f.write(\"\\nSuzuki params:\\n\")\n","    f.write(\"Suzuki_t=%s\\n\" % inter_t)\n","    f.write(\"Suzuki_lr=%s\\n\" % inter_lr)\n","\n","    # Training\n","    # Intra\n","\n","    # Intra best performance\n","    intra_best = [0, 0, 0, 0, [], []]  # train_R2, train_RMSE, test_R2, test_RMSE, test_predict, test_true\n","\n","    f.write(\"\\nIntra Start training\\n\")\n","\n","    for epoch in tqdm(range(intra_t)):\n","        # Training\n","        global_loss = torch.tensor([0.])\n","\n","        for data in intra_train_loader:\n","            x = data[:-1][0].cuda()\n","            y = torch.unsqueeze(data[-1], dim=1).cuda()\n","            loss = intra_criterion(intra_model.forward(x).float(), y.float())\n","            intra_opti.zero_grad()\n","            loss.backward()\n","            intra_opti.step()\n","            global_loss += loss.item()\n","\n","        # record of loss during training\n","        # performance in train set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in intra_train_loader:\n","                x = data[:-1][0].cuda()\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(intra_model.forward(x).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            intra_train_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            intra_train_R2.append(R2(np.array(pred), np.array(true)))\n","\n","        # performance in test set\n","        with torch.no_grad():\n","            intra_pred = list()\n","            intra_true = list()\n","            for data in test_loader:\n","                x = data[:-1][0].cuda()\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(intra_model.forward(x).cpu().detach().numpy())\n","                intra_pred += pr\n","                intra_true += tr\n","            intra_test_RMSE.append(RMSE(np.array(intra_pred), np.array(intra_true)))\n","            intra_test_R2.append(R2(np.array(intra_pred), np.array(intra_true)))\n","\n","            if epoch == 0 or intra_test_R2[-1] > intra_best[2]:\n","                intra_best = [intra_train_R2[-1], intra_train_RMSE[-1], intra_test_R2[-1], intra_test_RMSE[-1],\n","                              intra_pred, intra_true]\n","\n","    # Evaluation\n","    f.write(\"\\n\")\n","    f.write(\"Intra dataset Performance\\n\")\n","    # Performance in train set\n","    f.write(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(intra_train_R2[-10:]).mean(), np.array(intra_train_R2[-10:]).std(), intra_best[0]))\n","    f.write(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(intra_train_RMSE[-10:]).mean(), np.array(intra_train_RMSE[-10:]).std(), intra_best[1]))\n","\n","    # Performance in test set\n","    f.write(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(intra_test_R2[-10:]).mean(), np.array(intra_test_R2[-10:]).std(), intra_best[2]))\n","    f.write(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(intra_test_RMSE[-10:]).mean(), np.array(intra_test_RMSE[-10:]).std(), intra_best[3]))\n","\n","    # Figure\n","    fig = plt.figure(dpi=120, figsize=(20, 7))\n","\n","    # Training Fig\n","    plt.subplot(1, 2, 1)\n","    steps = np.linspace(1, intra_t, intra_t)\n","    plt.plot(steps, intra_train_RMSE, color=[236 / 255, 164 / 255, 124 / 255])\n","    plt.plot(steps, intra_test_RMSE, color=[117 / 255, 157 / 255, 219 / 255])\n","    # Beautify\n","    plt.legend([\"train set RMSE\", \"test set RMSE\"], loc=\"upper left\", prop={'size': 10})\n","    plt.xlabel(\"Epoch\", fontsize=10)\n","    plt.ylabel(\"RMSE\", fontsize=10)\n","    plt.title(\"The RMSE value during training\", fontsize=13)\n","\n","    # Test set performance\n","    plt.subplot(1, 2, 2)\n","    intra_tr = np.array(intra_best[5]).flatten() * 100\n","    intra_pr = np.array(intra_best[4]).flatten() * 100\n","    plt.scatter(intra_pr, intra_tr, alpha=0.7, marker=\".\")\n","    plt.xlabel(\"Predicted Yield\", fontsize=10)\n","    plt.ylabel(\"Observed Yield\", fontsize=10)\n","    x = np.linspace(0, 100, 100)\n","    y = np.linspace(0, 100, 100)\n","    plt.plot(x, y, linestyle=\"--\", color=\"r\")\n","    plt.title(\"Test set performance\", fontsize=15)\n","\n","    fig.suptitle(\"Intramolecular dataset addition(n_Sample=%d)\" % n_sample, fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(\"%s/Intramolecular dataset addition Performance Figure.png\" % dir_path)\n","    plt.show()\n","\n","    # Training\n","    # Inter\n","\n","    # Inter best performance\n","    inter_best = [0, 0, 0, 0, [], []]  # train_R2, train_RMSE, test_R2, test_RMSE, test_predict, test_true\n","\n","    f.write(\"\\nInter Start training\\n\")\n","\n","    for epoch in tqdm(range(inter_t)):\n","        # Training\n","        global_loss = torch.tensor([0.])\n","\n","        for data in inter_train_loader:\n","            x = data[:-1][0].cuda()\n","            y = torch.unsqueeze(data[-1], dim=1).cuda()\n","            loss = inter_criterion(inter_model.forward(x).float(), y.float())\n","            inter_opti.zero_grad()\n","            loss.backward()\n","            inter_opti.step()\n","            global_loss += loss.item()\n","\n","        # record of loss during training\n","        # performance in train set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in inter_train_loader:\n","                x = data[:-1][0].cuda()\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(inter_model.forward(x).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            inter_train_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            inter_train_R2.append(R2(np.array(pred), np.array(true)))\n","\n","        # performance in test set\n","        with torch.no_grad():\n","            inter_pred = list()\n","            inter_true = list()\n","            for data in test_loader:\n","                x = data[:-1][0].cuda()\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(inter_model.forward(x).cpu().detach().numpy())\n","                inter_pred += pr\n","                inter_true += tr\n","            inter_test_RMSE.append(RMSE(np.array(inter_pred), np.array(inter_true)))\n","            inter_test_R2.append(R2(np.array(inter_pred), np.array(inter_true)))\n","\n","            if epoch == 0 or inter_test_R2[-1] > inter_best[2]:\n","                inter_best = [inter_train_R2[-1], inter_train_RMSE[-1], inter_test_R2[-1], inter_test_RMSE[-1],\n","                              inter_pred, inter_true]\n","    # Evaluation\n","    f.write(\"\\n\")\n","    f.write(\"Inter dataset Performance\\n\")\n","    # Performance in train set\n","    f.write(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(inter_train_R2[-10:]).mean(), np.array(inter_train_R2[-10:]).std(), inter_best[0]))\n","    f.write(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(inter_train_RMSE[-10:]).mean(), np.array(inter_train_RMSE[-10:]).std(), inter_best[1]))\n","\n","    # Performance in test set\n","    f.write(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(inter_test_R2[-10:]).mean(), np.array(inter_test_R2[-10:]).std(), inter_best[2]))\n","    f.write(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(inter_test_RMSE[-10:]).mean(), np.array(inter_test_RMSE[-10:]).std(), inter_best[3]))\n","\n","    # Figure\n","    fig = plt.figure(dpi=120, figsize=(20, 7))\n","\n","    # Training Fig\n","    plt.subplot(1, 2, 1)\n","    steps = np.linspace(1, inter_t, inter_t)\n","    plt.plot(steps, inter_train_RMSE, color=[236 / 255, 164 / 255, 124 / 255])\n","    plt.plot(steps, inter_test_RMSE, color=[117 / 255, 157 / 255, 219 / 255])\n","    # Beautify\n","    plt.legend([\"train set RMSE\", \"test set RMSE\"], loc=\"upper left\", prop={'size': 10})\n","    plt.xlabel(\"Epoch\", fontsize=10)\n","    plt.ylabel(\"RMSE value\", fontsize=10)\n","    plt.title(\"The RMSE value during training\", fontsize=13)\n","\n","    # Test set performance\n","    plt.subplot(1, 2, 2)\n","    inter_tr = np.array(inter_best[5]).flatten() * 100\n","    inter_pr = np.array(inter_best[4]).flatten() * 100\n","    plt.scatter(inter_pr, inter_tr, alpha=0.7, marker=\".\")\n","    plt.xlabel(\"Predicted Yield\", fontsize=10)\n","    plt.ylabel(\"Observed Yield\", fontsize=10)\n","    x = np.linspace(0, 100, 100)\n","    y = np.linspace(0, 100, 100)\n","    plt.plot(x, y, linestyle=\"--\", color=\"r\")\n","    plt.title(\"Test set performance\", fontsize=15)\n","\n","    fig.suptitle(\"Intermolecular dataset addition(n_Sample=%d)\" % n_sample, fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(\"%s/Intermolecular dataset addition Performance Figure.png\" % dir_path)\n","    plt.show()\n","\n","    # Training\n","    # BH\n","\n","    # BH best performance\n","    BH_best = [0, 0, 0, 0, [], []]  # train_R2, train_RMSE, test_R2, test_RMSE, test_predict, test_true\n","\n","    f.write(\"\\nBH Start training\\n\")\n","\n","    for epoch in tqdm(range(BH_t)):\n","        # Training\n","        global_loss = torch.tensor([0.])\n","\n","        for data in BH_train_loader:\n","            x = data[:-1][0].cuda()\n","            y = torch.unsqueeze(data[-1], dim=1).cuda()\n","            loss = BH_criterion(BH_model.forward(x).float(), y.float())\n","            BH_opti.zero_grad()\n","            loss.backward()\n","            BH_opti.step()\n","            global_loss += loss.item()\n","\n","        # record of loss during training\n","        # performance in train set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in BH_train_loader:\n","                x = data[:-1][0].cuda()\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(BH_model.forward(x).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            BH_train_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            BH_train_R2.append(R2(np.array(pred), np.array(true)))\n","\n","        # performance in test set\n","        with torch.no_grad():\n","            BH_pred = list()\n","            BH_true = list()\n","            for data in test_loader:\n","                x = data[:-1][0].cuda()\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(BH_model.forward(x).cpu().detach().numpy())\n","                BH_pred += pr\n","                BH_true += tr\n","            BH_test_RMSE.append(RMSE(np.array(BH_pred), np.array(BH_true)))\n","            BH_test_R2.append(R2(np.array(BH_pred), np.array(BH_true)))\n","\n","            if epoch == 0 or BH_test_R2[-1] > BH_best[2]:\n","                BH_best = [BH_train_R2[-1], BH_train_RMSE[-1], BH_test_R2[-1], BH_test_RMSE[-1], BH_pred, BH_true]\n","    # Evaluation\n","    f.write(\"\\n\")\n","    f.write(\"BH dataset Performance\\n\")\n","    # Performance in train set\n","    f.write(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(BH_train_R2[-10:]).mean(), np.array(BH_train_R2[-10:]).std(), BH_best[0]))\n","    f.write(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(BH_train_RMSE[-10:]).mean(), np.array(BH_train_RMSE[-10:]).std(), BH_best[1]))\n","\n","    # Performance in test set\n","    f.write(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(BH_test_R2[-10:]).mean(), np.array(BH_test_R2[-10:]).std(), BH_best[2]))\n","    f.write(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(BH_test_RMSE[-10:]).mean(), np.array(BH_test_RMSE[-10:]).std(), BH_best[3]))\n","\n","    # Figure\n","    fig = plt.figure(dpi=120, figsize=(20, 7))\n","\n","    # Training Fig\n","    plt.subplot(1, 2, 1)\n","    steps = np.linspace(1, BH_t, BH_t)\n","    plt.plot(steps, BH_train_RMSE, color=[236 / 255, 164 / 255, 124 / 255])\n","    plt.plot(steps, BH_test_RMSE, color=[117 / 255, 157 / 255, 219 / 255])\n","    # Beautify\n","    plt.legend([\"train set RMSE\", \"test set RMSE\"], loc=\"upper left\", prop={'size': 10})\n","    plt.xlabel(\"Epoch\", fontsize=10)\n","    plt.ylabel(\"RMSE value\", fontsize=10)\n","    plt.title(\"The RMSE value uring training\", fontsize=13)\n","\n","    # Test set performance\n","    plt.subplot(1, 2, 2)\n","    BH_tr = np.array(BH_best[5]).flatten() * 100\n","    BH_pr = np.array(BH_best[4]).flatten() * 100\n","    plt.scatter(BH_pr, BH_tr, alpha=0.7, marker=\".\")\n","    plt.xlabel(\"Predicted Yield\", fontsize=10)\n","    plt.ylabel(\"Observed Yield\", fontsize=10)\n","    x = np.linspace(0, 100, 100)\n","    y = np.linspace(0, 100, 100)\n","    plt.plot(x, y, linestyle=\"--\", color=\"r\")\n","    plt.title(\"Test set performance\", fontsize=15)\n","\n","    fig.suptitle(\"Buchwald Hartwig dataset addition(n_Sample=%d)\" % n_sample, fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(\"%s/Buchwald Hartwig dataset addition Performance Figure.png\" % dir_path)\n","    plt.show()\n","\n","    # Training\n","    # Suzuki\n","\n","    # Suzuki best performance\n","    Suzuki_best = [0, 0, 0, 0, [], []]  # train_R2, train_RMSE, test_R2, test_RMSE, test_predict, test_true\n","\n","    f.write(\"\\nSuzuki Start training\\n\")\n","\n","    for epoch in tqdm(range(Suzuki_t)):\n","        # Training\n","        global_loss = torch.tensor([0.])\n","\n","        for data in Suzuki_train_loader:\n","            x = data[:-1][0].cuda()\n","            y = torch.unsqueeze(data[-1], dim=1).cuda()\n","            loss = Suzuki_criterion(Suzuki_model.forward(x).float(), y.float())\n","            Suzuki_opti.zero_grad()\n","            loss.backward()\n","            Suzuki_opti.step()\n","            global_loss += loss.item()\n","\n","        # record of loss during training\n","        # performance in train set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in Suzuki_train_loader:\n","                x = data[:-1][0].cuda()\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(Suzuki_model.forward(x).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            Suzuki_train_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            Suzuki_train_R2.append(R2(np.array(pred), np.array(true)))\n","\n","        # performance in test set\n","        with torch.no_grad():\n","            Suzuki_pred = list()\n","            Suzuki_true = list()\n","            for data in test_loader:\n","                x = data[:-1][0].cuda()\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(Suzuki_model.forward(x).cpu().detach().numpy())\n","                Suzuki_pred += pr\n","                Suzuki_true += tr\n","            Suzuki_test_RMSE.append(RMSE(np.array(Suzuki_pred), np.array(Suzuki_true)))\n","            Suzuki_test_R2.append(R2(np.array(Suzuki_pred), np.array(Suzuki_true)))\n","\n","            if epoch == 0 or Suzuki_test_R2[-1] > Suzuki_best[2]:\n","                Suzuki_best = [Suzuki_train_R2[-1], Suzuki_train_RMSE[-1], Suzuki_test_R2[-1], Suzuki_test_RMSE[-1],\n","                               Suzuki_pred, Suzuki_true]\n","    # Evaluation\n","    f.write(\"\\n\")\n","    f.write(\"Suzuki dataset Performance\\n\")\n","    # Performance in train set\n","    f.write(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(Suzuki_train_R2[-10:]).mean(), np.array(Suzuki_train_R2[-10:]).std(), Suzuki_best[0]))\n","    f.write(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(Suzuki_train_RMSE[-10:]).mean(), np.array(Suzuki_train_RMSE[-10:]).std(), Suzuki_best[1]))\n","\n","    # Performance in test set\n","    f.write(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(Suzuki_test_R2[-10:]).mean(), np.array(Suzuki_test_R2[-10:]).std(), Suzuki_best[2]))\n","    f.write(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(Suzuki_test_RMSE[-10:]).mean(), np.array(Suzuki_test_RMSE[-10:]).std(), Suzuki_best[3]))\n","\n","    # Figure\n","    fig = plt.figure(dpi=120, figsize=(20, 7))\n","\n","    # Training Fig\n","    plt.subplot(1, 2, 1)\n","    steps = np.linspace(1, Suzuki_t, Suzuki_t)\n","    plt.plot(steps, Suzuki_train_RMSE, color=[236 / 255, 164 / 255, 124 / 255])\n","    plt.plot(steps, Suzuki_test_RMSE, color=[117 / 255, 157 / 255, 219 / 255])\n","    # Beautify\n","    plt.legend([\"train set RMSE\", \"test set RMSE\"], loc=\"upper left\", prop={'size': 10})\n","    plt.xlabel(\"Epoch\", fontsize=10)\n","    plt.ylabel(\"RMSE value\", fontsize=10)\n","    plt.title(\"The RMSE value during training\", fontsize=13)\n","\n","    # Test set performance\n","    plt.subplot(1, 2, 2)\n","    Suzuki_tr = np.array(Suzuki_best[5]).flatten() * 100\n","    Suzuki_pr = np.array(Suzuki_best[4]).flatten() * 100\n","    plt.scatter(Suzuki_pr, Suzuki_tr, alpha=0.7, marker=\".\")\n","    plt.xlabel(\"Predicted Yield\", fontsize=10)\n","    plt.ylabel(\"Observed Yield\", fontsize=10)\n","    x = np.linspace(0, 100, 100)\n","    y = np.linspace(0, 100, 100)\n","    plt.plot(x, y, linestyle=\"--\", color=\"r\")\n","    plt.title(\"Test set performance\", fontsize=15)\n","\n","    fig.suptitle(\"Suzuki dataset addition(n_Sample=%d)\" % n_sample, fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(\"%s/Suzuki dataset addition Performance Figure.png\" % dir_path)\n","    plt.show()\n","\n","    f.close()"]},{"cell_type":"code","source":[],"metadata":{"id":"md_yp-OTONLt"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"authorship_tag":"ABX9TyOmTCj/+fHMIcWHlwDF9yPI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}