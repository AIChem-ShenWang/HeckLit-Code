This project is the code for the paper "A Benchmarking Study of a Large-scale Heck Reaction Yield Dataset using Subgroup-based Modeling", including the dataset used and the code for model training, testing, and interpretive result generation.

The project uses Python in combination with the GPU provided by the Colab (https://colab.research.google.com/) to build and train the model.The required python version and python libraries are listed in pkgs.txt.

The project consists of 6 folders: data, data_process, exp, figures, models, utils. Each of which is described below.

* data folder:

  * BH_HTE: Buchwald-Hartwig reaction high-throughput experimentation dataset

  * Suzuki_HTE: Suzuki-Miyaura reaction high-throughput  experimentation dataset

  * Heck: HeckLit literature-based yield dataset, constructed based on Reaxys (https://www.reaxys.com)

Among them, 

* data_process folder:

* exp folder:

  * BH, Suzuki, AT, SNARï¼ŒELN: The files named after the datasets in 4 HTE cases include the training and testing code for MMHRP-GCL, as well as the training test code for the replicated SOTA model, and a challenging dataset (ELN) containing the code for MMHRP-GCL.

  * Interpretability: Codes for generating model interpretability results
 
  * LVA: Codes and results for the analysis of latent vetors in different modality

* figures




* models folder:

  * FP_generator.py: Used to convert Reaction SMILES to RXNFP and DRFP.

  * MMHRP.py: The framework of MMHRP-GCL

  * GNN_Models.py: GCN models and GAT model frameworks

  * vocab_generator.py: Smi2Vec models


* utils folder: 

  * BH_vocab.txt, Suzuki_vocab.txt, AT_vocab.txt, SNAR_vocab.txt, ELN_vocab.txt: Dictionaries for the 5-case dataset, txt files, generated by the Smi2Vec model. 

  * molecule.py, rxn.py: The py files are auxiliary toolkits for dealing with molecules and reaction data


